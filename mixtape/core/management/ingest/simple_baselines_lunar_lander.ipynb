{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q swig\n",
        "!pip install -q gymnasium[box2d]\n",
        "!pip install -q stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "i4kcJCzdFx0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXUdniaVEEqi"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import gymnasium as gym\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from stable_baselines3 import PPO\n",
        "from itertools import count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def render_env_base64(env):\n",
        "    frame = env.render()\n",
        "    img = Image.fromarray(frame)\n",
        "    buf = BytesIO()\n",
        "    img.save(buf, format='PNG')\n",
        "    return base64.b64encode(buf.getvalue()).decode('utf-8')"
      ],
      "metadata": {
        "id": "LVwvWENJFOJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set default values\n",
        "env_name = 'LunarLander-v3'\n",
        "iterations = 100  # Match the default value that MIXTAPE uses\n",
        "train_batch_size = 64  # Match the default value that MIXTAPE uses"
      ],
      "metadata": {
        "id": "_UKB4MDPJXKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build output\n",
        "output = {\n",
        "    'action_mapping': {\n",
        "        '0': 'None',\n",
        "        '1': 'Left engine',\n",
        "        '2': 'Main engine',\n",
        "        '3': 'Right engine'\n",
        "    },\n",
        "    'training': {\n",
        "        'environment': env_name,\n",
        "        'algorithm': 'PPO',\n",
        "        'iterations': iterations,\n",
        "        'config': {},\n",
        "    },\n",
        "    'inference': {\n",
        "        'parallel': False,\n",
        "        'config': {},\n",
        "        'steps': []\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "jWPognhAKM8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_path = \"ppo_cartpole_sb3\"\n",
        "train_env = gym.make(\"LunarLander-v3\")\n",
        "model = PPO(\"MlpPolicy\", train_env, verbose=0)\n",
        "# NOTE: The Stable Baselines3 library does not have a way to specify the number of training iterations\n",
        "# like we do in the MIXTAPE system. In order to match what the MIXTAPE system does as closely as\n",
        "# possible, we set the total_timesteps to be the same as the train_batch_size that we use in MIXTAPE and\n",
        "# the number of iterations to be the same as the default number of training iterations.\n",
        "for i in range(iterations):\n",
        "  model.learn(total_timesteps=train_batch_size, reset_num_timesteps=False)\n",
        "model.save(model_path)\n",
        "output['training']['config'] = model.get_parameters()['policy.optimizer']['param_groups'][0]"
      ],
      "metadata": {
        "id": "FRtoxWZwHWo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference and log data\n",
        "env_id = \"LunarLander-v3\"\n",
        "env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "\n",
        "for step_num in count():\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "    frame_b64 = render_env_base64(env)\n",
        "    output['inference']['steps'].append({\n",
        "        \"number\": step_num,\n",
        "        \"image\": frame_b64,\n",
        "        \"agent_steps\": [\n",
        "            {\n",
        "                \"agent\": \"agent_0\",\n",
        "                \"action\": int(action),\n",
        "                \"reward\": float(reward),\n",
        "                \"observation_space\": np.array(obs).tolist()\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "    obs = next_obs\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "AHpdF7woFhdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write log to JSON file\n",
        "with open(\"stable_baselines_example.json\", \"w\") as f:\n",
        "    json.dump(output, f, indent=2)"
      ],
      "metadata": {
        "id": "qLGi7zJvFkBj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
